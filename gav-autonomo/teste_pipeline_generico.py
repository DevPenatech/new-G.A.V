# gav-autonomo/teste_pipeline_generico.py
# Testa pipeline 100% prompt-driven (sem regras hardcoded)

import requests
import json

BASE_URL = "http://localhost:8000"

def teste_llm_selector_deteccao():
    """Testa se LLM Selector detecta corretamente contexto vs busca nova"""
    
    print("ðŸ§  TESTE: DetecÃ§Ã£o do LLM Selector")
    print("=" * 40)
    
    cenarios = [
        {
            "tipo": "busca_nova",
            "mensagem": "quero nescau",
            "endpoint_esperado": "/produtos/busca"
        },
        {
            "tipo": "contexto_anterior", 
            "mensagem": "quero o 1",
            "endpoint_esperado": "/chat/contexto"
        },
        {
            "tipo": "contexto_anterior",
            "mensagem": "id 18136", 
            "endpoint_esperado": "/chat/contexto"
        },
        {
            "tipo": "contexto_anterior",
            "mensagem": "ver mais opÃ§Ãµes",
            "endpoint_esperado": "/chat/contexto"
        },
        {
            "tipo": "carrinho",
            "mensagem": "ver meu carrinho",
            "endpoint_esperado": "/carrinhos/"
        },
        {
            "tipo": "conversa",
            "mensagem": "obrigado",
            "endpoint_esperado": "/chat/resposta"
        }
    ]
    
    sucessos = 0
    total = len(cenarios)
    
    print("ðŸ“‹ CenÃ¡rios de teste:")
    for i, cenario in enumerate(cenarios, 1):
        print(f"   {i}. {cenario['tipo']}: '{cenario['mensagem']}'")
    
    print("\nðŸ§ª Executando testes...")
    
    for i, cenario in enumerate(cenarios, 1):
        print(f"\n{i}. Testando: '{cenario['mensagem']}'")
        
        try:
            response = requests.post(f"{BASE_URL}/chat", json={
                "texto": cenario["mensagem"],
                "sessao_id": f"test_detector_{i}"
            }, timeout=30)
            
            if response.status_code == 200:
                resultado = response.json()
                
                # Para validar, vemos se a resposta faz sentido para o tipo
                if cenario["tipo"] == "busca_nova":
                    # Deve buscar produtos
                    if "encontrei" in resultado.get("mensagem", "").lower() or "resultados" in resultado:
                        print("âœ… Busca nova detectada corretamente")
                        sucessos += 1
                    else:
                        print("âŒ Busca nova NÃƒO detectada")
                        
                elif cenario["tipo"] == "contexto_anterior":
                    # Deve tentar processar contexto (pode dar erro por nÃ£o ter contexto)
                    mensagem = resultado.get("mensagem", "").lower()
                    if "erro" in resultado or "nÃ£o consegui" in mensagem or "contexto" in mensagem:
                        print("âœ… Contexto anterior detectado (sem contexto disponÃ­vel Ã© OK)")
                        sucessos += 1
                    else:
                        print("âŒ Contexto anterior NÃƒO detectado")
                        
                elif cenario["tipo"] == "carrinho":
                    # Deve processar carrinho
                    if "carrinho" in resultado.get("mensagem", "").lower():
                        print("âœ… Carrinho detectado corretamente")
                        sucessos += 1
                    else:
                        print("âŒ Carrinho NÃƒO detectado")
                        
                elif cenario["tipo"] == "conversa":
                    # Deve responder conversacionalmente
                    if resultado.get("tipo") == "conversacional" or len(resultado.get("mensagem", "")) > 10:
                        print("âœ… Conversa detectada corretamente")
                        sucessos += 1
                    else:
                        print("âŒ Conversa NÃƒO detectada")
                
                # Debug da resposta
                print(f"   ðŸ“ Resposta: {json.dumps(resultado, ensure_ascii=False)[:100]}...")
                
            else:
                print(f"âŒ Erro HTTP: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ Erro na requisiÃ§Ã£o: {e}")
    
    print(f"\nðŸ“Š Resultado: {sucessos}/{total} detecÃ§Ãµes corretas ({sucessos/total*100:.1f}%)")
    
    if sucessos >= total * 0.8:
        print("âœ… LLM Selector funcionando bem!")
        return True
    else:
        print("âŒ LLM Selector precisa de ajustes")
        return False

def teste_pipeline_generico():
    """Testa se o pipeline genÃ©rico funciona para diferentes domÃ­nios"""
    
    print("\nðŸ”„ TESTE: Pipeline GenÃ©rico")
    print("=" * 35)
    
    # Testa diferentes tipos de interaÃ§Ã£o
    interacoes = [
        ("Busca de produto", "quero cafÃ©"),
        ("OperaÃ§Ã£o carrinho", "ver carrinho"),  
        ("Conversa casual", "oi, tudo bem?"),
        ("Agradecimento", "muito obrigado!")
    ]
    
    sucessos = 0
    
    for tipo, mensagem in interacoes:
        print(f"\nðŸ§ª {tipo}: '{mensagem}'")
        
        try:
            response = requests.post(f"{BASE_URL}/chat", json={
                "texto": mensagem,
                "sessao_id": "test_pipeline_generico"
            })
            
            if response.status_code == 200:
                resultado = response.json()
                
                # Verifica se tem resposta conversacional
                if "mensagem" in resultado and len(resultado["mensagem"]) > 5:
                    print(f"âœ… Pipeline funcionou: {resultado['mensagem'][:50]}...")
                    sucessos += 1
                else:
                    print("âŒ Pipeline nÃ£o gerou resposta conversacional")
                    print(f"   ðŸ“ Resposta: {json.dumps(resultado, indent=2)[:150]}...")
            else:
                print(f"âŒ Erro HTTP: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ Erro: {e}")
    
    print(f"\nðŸ“Š Pipeline: {sucessos}/{len(interacoes)} funcionando ({sucessos/len(interacoes)*100:.1f}%)")
    
    return sucessos >= len(interacoes) * 0.75

def teste_prompts_contexto():
    """Testa se os prompts de contexto foram criados corretamente"""
    
    print("\nðŸŽ¯ TESTE: Prompts de Contexto")
    print("=" * 32)
    
    prompts_necessarios = [
        "prompt_processador_contexto",
        "prompt_executor_referencia"
    ]
    
    sucessos = 0
    
    for prompt_nome in prompts_necessarios:
        print(f"\nðŸ” Verificando: {prompt_nome}")
        
        try:
            response = requests.get(f"http://localhost:8001/admin/prompts/buscar", params={
                "nome": prompt_nome,
                "espaco": "autonomo",
                "versao": "1"
            })
            
            if response.status_code == 200:
                prompt_data = response.json()
                
                if prompt_data.get("template") and len(prompt_data["template"]) > 100:
                    print("âœ… Prompt existe e tem conteÃºdo")
                    sucessos += 1
                else:
                    print("âŒ Prompt vazio ou muito pequeno")
            else:
                print(f"âŒ Prompt nÃ£o encontrado: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ Erro ao verificar prompt: {e}")
    
    print(f"\nðŸ“Š Prompts: {sucessos}/{len(prompts_necessarios)} criados ({sucessos/len(prompts_necessarios)*100:.1f}%)")
    
    return sucessos == len(prompts_necessarios)

def teste_arquitetura_generica():
    """Testa se a arquitetura Ã© realmente genÃ©rica (nÃ£o especÃ­fica de produtos)"""
    
    print("\nðŸ—ï¸ TESTE: Arquitetura GenÃ©rica")
    print("=" * 35)
    
    # Simula diferentes domÃ­nios
    dominios = [
        ("Vendas", "quero um produto"),
        ("Suporte", "preciso de ajuda"),
        ("Agendamento", "quero marcar uma consulta"),
        ("InformaÃ§Ãµes", "qual o horÃ¡rio de funcionamento?")
    ]
    
    generico = True
    
    for dominio, mensagem in dominios:
        print(f"\nðŸŒ Simulando {dominio}: '{mensagem}'")
        
        try:
            response = requests.post(f"{BASE_URL}/chat", json={
                "texto": mensagem,
                "sessao_id": f"test_{dominio.lower()}"
            })
            
            if response.status_code == 200:
                resultado = response.json()
                
                # Verifica se o sistema responde genericamente (nÃ£o quebra)
                if "mensagem" in resultado or "erro" in resultado:
                    print(f"âœ… Sistema genÃ©rico respondeu: {str(resultado)[:50]}...")
                else:
                    print("âŒ Sistema nÃ£o Ã© genÃ©rico (quebrou com domÃ­nio diferente)")
                    generico = False
            else:
                print(f"âš ï¸ Sistema retornou erro: {response.status_code}")
                # Erro pode ser OK, desde que seja tratado genericamente
                
        except Exception as e:
            print(f"âŒ Sistema quebrou com domÃ­nio diferente: {e}")
            generico = False
    
    if generico:
        print("\nâœ… ARQUITETURA Ã‰ GENÃ‰RICA: Funciona para qualquer domÃ­nio!")
        print("ðŸš€ Pronto para: vendas, telemarking, suporte, agendamento, etc.")
    else:
        print("\nâŒ ARQUITETURA NÃƒO Ã‰ GENÃ‰RICA: Acoplada a produtos")
        
    return generico

def executar_suite_correcao():
    """Executa todos os testes da soluÃ§Ã£o corrigida"""
    
    print("ðŸŽ¯ SUITE DE TESTES: SoluÃ§Ã£o 100% Prompt-Driven")
    print("=" * 60)
    
    resultados = {
        "deteccao_llm": teste_llm_selector_deteccao(),
        "pipeline_generico": teste_pipeline_generico(), 
        "prompts_contexto": teste_prompts_contexto(),
        "arquitetura_generica": teste_arquitetura_generica()
    }
    
    # RelatÃ³rio final
    print("\n" + "=" * 60)
    print("ðŸ“Š RELATÃ“RIO FINAL - CORREÃ‡ÃƒO IMPLEMENTADA")
    print("=" * 60)
    
    sucessos = sum(resultados.values())
    total = len(resultados)
    
    print(f"âœ… DetecÃ§Ã£o LLM: {'PASSOU' if resultados['deteccao_llm'] else 'FALHOU'}")
    print(f"âœ… Pipeline GenÃ©rico: {'PASSOU' if resultados['pipeline_generico'] else 'FALHOU'}")
    print(f"âœ… Prompts de Contexto: {'PASSOU' if resultados['prompts_contexto'] else 'FALHOU'}")
    print(f"âœ… Arquitetura GenÃ©rica: {'PASSOU' if resultados['arquitetura_generica'] else 'FALHOU'}")
    
    print(f"\nðŸŽ¯ RESULTADO GERAL: {sucessos}/{total} ({sucessos/total*100:.1f}%)")
    
    if sucessos == total:
        print("\nðŸŽ‰ PERFEITO! SoluÃ§Ã£o 100% Prompt-Driven implementada!")
        print("ðŸš€ Sistema genÃ©rico para qualquer domÃ­nio")
        print("âœ… Zero regras hardcoded mantido")
        print("ðŸ§  Arquitetura evolutiva via prompt")
        
    elif sucessos >= total * 0.75:
        print("\nâœ… MUITO BOM! CorreÃ§Ã£o principal implementada")
        print("ðŸ”§ Pequenos ajustes nos prompts podem melhorar")
        
    else:
        print("\nðŸ”§ PRECISA AJUSTES: Verificar prompts e implementaÃ§Ã£o")
        print("ðŸ’¡ Lembrar: TUDO via prompt, zero regras hardcoded")
    
    return sucessos / total

if __name__ == "__main__":
    executar_suite_correcao()