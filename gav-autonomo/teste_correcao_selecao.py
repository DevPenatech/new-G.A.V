#!/usr/bin/env python3
# teste_correcao_selecao.py
# Valida se as correÃ§Ãµes do LLM Selector funcionaram

import requests
import json
import time
from typing import Dict, Any

BASE_URL = "http://localhost:8000"

def teste_fluxo_completo_corrigido():
    """Testa o fluxo completo: busca numerada â†’ seleÃ§Ã£o â†’ confirmaÃ§Ã£o"""
    
    print("ğŸ”„ TESTE CRÃTICO: Fluxo SeleÃ§Ã£o por Contexto")
    print("=" * 50)
    
    sessao_teste = f"test_correcao_{int(time.time())}"
    
    # ETAPA 1: Busca deve retornar produtos numerados
    print("1ï¸âƒ£ Busca inicial para criar contexto...")
    
    response1 = requests.post(f"{BASE_URL}/chat", json={
        "texto": "quero nescau",
        "sessao_id": sessao_teste
    }, timeout=300)
    
    if response1.status_code != 200:
        print(f"âŒ FALHA: Busca inicial falhou com status {response1.status_code}")
        return False
    
    resultado1 = response1.json()
    mensagem1 = resultado1.get("mensagem", "")
    
    # Verifica se produtos foram numerados
    if not ("1ï¸âƒ£" in mensagem1 and "2ï¸âƒ£" in mensagem1):
        print(f"âŒ FALHA: Produtos nÃ£o estÃ£o numerados na busca")
        print(f"   Resposta: {mensagem1[:200]}...")
        return False
    
    print(f"âœ… Busca OK - produtos numerados encontrados")
    print(f"   Exemplo: {mensagem1[:100]}...")
    
    # ETAPA 2: SeleÃ§Ã£o "quero o 1" deve processar contexto
    print(f"\n2ï¸âƒ£ Tentando seleÃ§Ã£o por nÃºmero...")
    time.sleep(1)  # Pequena pausa para o sistema processar
    
    response2 = requests.post(f"{BASE_URL}/chat", json={
        "texto": "quero o 1",
        "sessao_id": sessao_teste  # MESMA sessÃ£o!
    }, timeout=300)
    
    if response2.status_code != 200:
        print(f"âŒ FALHA: SeleÃ§Ã£o falhou com status {response2.status_code}")
        return False
    
    resultado2 = response2.json()
    mensagem2 = resultado2.get("mensagem", "").lower()
    
    # Verifica se processou a seleÃ§Ã£o corretamente
    sucesso_selecao = any(indicador in mensagem2 for indicador in [
        "adicionado", "carrinho", "item", "produto"
    ])
    
    if sucesso_selecao:
        print(f"âœ… CORREÃ‡ÃƒO FUNCIONOU: SeleÃ§Ã£o processada corretamente!")
        print(f"   Resposta: {resultado2.get('mensagem', '')[:150]}...")
        return True
    else:
        print(f"âŒ FALHA: SeleÃ§Ã£o ainda nÃ£o funciona")
        print(f"   Resposta: {mensagem2[:150]}...")
        
        # Debug adicional
        if "nÃ£o consegui identificar" in mensagem2:
            print(f"   ğŸ” Problema: Sistema nÃ£o encontrou contexto")
        elif "nescau" in mensagem2:
            print(f"   ğŸ” Problema: Sistema fez nova busca em vez de seleÃ§Ã£o")
        
        return False

def teste_multiplos_tipos_referencia():
    """Testa diferentes tipos de referÃªncia ao contexto"""
    
    print(f"\nğŸ§ª TESTE ABRANGENTE: MÃºltiplos Tipos de ReferÃªncia")
    print("=" * 55)
    
    casos_referencia = [
        ("quero o 1", "nÃºmero direto"),
        ("o primeiro", "posiÃ§Ã£o por extenso"),
        ("id 18136", "referÃªncia por ID"),
        ("a lata pequena", "caracterÃ­stica"),
        ("ver mais opÃ§Ãµes", "expansÃ£o de resultados")
    ]
    
    sucessos = 0
    total = len(casos_referencia)
    
    for i, (caso, tipo) in enumerate(casos_referencia, 1):
        print(f"\n{i}. Testando {tipo}: '{caso}'")
        
        sessao = f"test_ref_{i}_{int(time.time())}"
        
        # Primeiro fazer busca para ter contexto
        requests.post(f"{BASE_URL}/chat", json={
            "texto": "quero nescau",
            "sessao_id": sessao
        })
        
        time.sleep(0.5)
        
        # Depois testar referÃªncia
        response = requests.post(f"{BASE_URL}/chat", json={
            "texto": caso,
            "sessao_id": sessao
        })
        
        if response.status_code == 200:
            resultado = response.json()
            mensagem = resultado.get("mensagem", "").lower()
            
            # Para "ver mais" esperamos expansÃ£o, para outros esperamos seleÃ§Ã£o
            if caso == "ver mais opÃ§Ãµes":
                sucesso = "mais" in mensagem or "opÃ§Ãµes" in mensagem
            else:
                sucesso = any(x in mensagem for x in ["adicionado", "carrinho", "item"])
            
            if sucesso:
                print(f"   âœ… {tipo} funcionou!")
                sucessos += 1
            else:
                print(f"   âŒ {tipo} nÃ£o funcionou")
                if "nÃ£o consegui identificar" in mensagem:
                    print(f"      Problema: NÃ£o encontrou contexto")
        else:
            print(f"   âŒ Erro HTTP: {response.status_code}")
    
    print(f"\nğŸ“Š Tipos de ReferÃªncia: {sucessos}/{total} funcionando ({sucessos/total*100:.1f}%)")
    return sucessos >= total * 0.8

def teste_deteccao_llm_selector():
    """Testa se LLM Selector agora detecta corretamente contexto vs busca nova"""
    
    print(f"\nğŸ§  TESTE ESPECÃFICO: DetecÃ§Ã£o LLM Selector")
    print("=" * 45)
    
    # Teste sem contexto anterior - deve detectar falta de contexto
    print(f"1. ReferÃªncia sem contexto anterior...")
    response_sem_contexto = requests.post(f"{BASE_URL}/chat", json={
        "texto": "quero o 1",
        "sessao_id": f"sem_contexto_{int(time.time())}"
    })
    
    if response_sem_contexto.status_code == 200:
        resultado = response_sem_contexto.json()
        mensagem = resultado.get("mensagem", "").lower()
        
        # Deve reconhecer que nÃ£o tem contexto
        if any(x in mensagem for x in ["nÃ£o consegui", "nÃ£o encontrei", "contexto", "mais detalhes"]):
            print("   âœ… Detectou corretamente falta de contexto")
        else:
            print("   âŒ NÃ£o detectou falta de contexto adequadamente")
    
    # Teste busca nova - deve ir para busca normal
    print(f"2. Busca nova (nÃ£o referÃªncia)...")
    response_busca_nova = requests.post(f"{BASE_URL}/chat", json={
        "texto": "quero cafÃ© pilÃ£o",
        "sessao_id": f"busca_nova_{int(time.time())}"
    })
    
    if response_busca_nova.status_code == 200:
        resultado = response_busca_nova.json()
        mensagem = resultado.get("mensagem", "").lower()
        
        # Deve fazer busca normal e mostrar produtos
        if "cafÃ©" in mensagem and ("encontrei" in mensagem or "opÃ§Ãµes" in mensagem):
            print("   âœ… Busca nova processada corretamente")
        else:
            print("   âŒ Busca nova nÃ£o processada corretamente")

def executar_validacao_completa():
    """Executa todos os testes de validaÃ§Ã£o das correÃ§Ãµes"""
    
    print("ğŸ¯ VALIDAÃ‡ÃƒO COMPLETA: CorreÃ§Ãµes LLM Selector")
    print("=" * 60)
    print("ğŸ“ Validando se correÃ§Ãµes no banco resolveram problemas de seleÃ§Ã£o")
    
    # Testa fluxo crÃ­tico principal
    fluxo_funcionando = teste_fluxo_completo_corrigido()
    
    # Testa diferentes tipos de referÃªncia
    referencias_funcionando = teste_multiplos_tipos_referencia()
    
    # Testa detecÃ§Ã£o especÃ­fica do LLM
    teste_deteccao_llm_selector()
    
    # RelatÃ³rio final
    print(f"\n{'=' * 60}")
    print("ğŸ“Š RELATÃ“RIO FINAL DA VALIDAÃ‡ÃƒO")
    print("=" * 60)
    
    if fluxo_funcionando and referencias_funcionando:
        print("ğŸ‰ CORREÃ‡Ã•ES BEM-SUCEDIDAS!")
        print("âœ… Fluxo principal funcionando")
        print("âœ… MÃºltiplos tipos de referÃªncia funcionando")
        print("âœ… LLM Selector detectando contexto corretamente")
        
        print(f"\nğŸš€ PRÃ“XIMOS PASSOS:")
        print("1. Executar teste completo da Fase 5a.2.1")
        print("2. Implementar formataÃ§Ã£o rica de preÃ§os")
        print("3. Adicionar emojis contextuais por categoria")
        
        return True
        
    elif fluxo_funcionando:
        print("âœ… PARCIALMENTE CORRIGIDO")
        print("âœ… Fluxo principal funcionando")
        print("ğŸ”§ Alguns tipos de referÃªncia precisam ajuste")
        
        return False
        
    else:
        print("âŒ CORREÃ‡Ã•ES AINDA NÃƒO SURTIRAM EFEITO")
        print("ğŸ”§ Problemas persistem:")
        print("   â€¢ Fluxo de seleÃ§Ã£o nÃ£o funciona")
        print("   â€¢ LLM Selector nÃ£o detecta contexto")
        
        print(f"\nğŸ’¡ VERIFICAÃ‡Ã•ES RECOMENDADAS:")
        print("1. Confirmar se SQLs foram executados no banco")
        print("2. Reiniciar gav_autonomo apÃ³s alteraÃ§Ãµes no banco")
        print("3. Verificar logs do LLM durante teste")
        print("4. Confirmar se prompt_api_call_selector versÃ£o 4 estÃ¡ ativo")
        
        return False

if __name__ == "__main__":
    try:
        print("ğŸ”§ INICIANDO VALIDAÃ‡ÃƒO DAS CORREÃ‡Ã•ES...")
        time.sleep(2)  # Aguarda sistema estar pronto
        
        sucesso = executar_validacao_completa()
        
        if sucesso:
            print(f"\nğŸ‰ FASE 5a.2.1 PRONTA PARA CONTINUAR!")
        else:
            print(f"\nğŸ”§ AJUSTES ADICIONAIS NECESSÃRIOS")
            
    except KeyboardInterrupt:
        print(f"\nâš¡ Teste interrompido pelo usuÃ¡rio")
    except Exception as e:
        print(f"\nâŒ Erro durante validaÃ§Ã£o: {e}")